{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.3"},"colab":{"name":"H5 File 2 - Calling_Cloud-microservices.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"Hjti103i8QFS","colab_type":"text"},"source":["# Homework #5 Deploy Model in GCP (File 2 of 2)\n","### File 1: Notebook to create the model and save the model on GCP AI platform\n","### File 2: Notebook that is calling the service on GCP AI platform\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"-GEdDAOS8QFU","colab_type":"text"},"source":["# Import Libraries"]},{"cell_type":"code","metadata":{"id":"C1zCprvK8QFV","colab_type":"code","colab":{}},"source":["from tensorflow import keras\n","import pandas as pd\n","import numpy as np\n","import os\n","import re\n","import spacy\n","from sklearn.preprocessing import LabelEncoder"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BOalnSfS8QFZ","colab_type":"code","colab":{}},"source":["import googleapiclient.discovery"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gVm_loiC8QFb","colab_type":"text"},"source":["# Load Secure Key"]},{"cell_type":"code","metadata":{"id":"L7VMZ9k28QFc","colab_type":"code","colab":{}},"source":["os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"utopian-rush-255612-b73345de1c22.json\""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KFusgz0a8QFe","colab_type":"text"},"source":["# Setup Environments and Functions"]},{"cell_type":"code","metadata":{"id":"rFDTTXWn8QFe","colab_type":"code","colab":{}},"source":["project_id = \"utopian-rush-255612\"\n","model_id = \"my_sentiment_analysis\"\n","model_path = \"projects/{}/models/{}\".format(project_id,model_id)\n","ml_resource = googleapiclient.discovery.build(\"ml\", \"v1\").projects()\n","output_name = 'dense_1'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lRVHM72H8QFh","colab_type":"code","colab":{}},"source":["def predict(X):\n","    input_data_json = {\"signature_name\": \"serving_default\", \"instances\": X.tolist()}\n","    request = ml_resource.predict(name=model_path, body=input_data_json)\n","    response = request.execute()\n","    if \"error\" in response:\n","        raise RuntimeError(response[\"error\"])\n","    return np.array([pred[output_name] for pred in response[\"predictions\"]])\n","    # return response[\"predictions\"]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nvPPQW7l8QFj","colab_type":"text"},"source":["# Generate tweets"]},{"cell_type":"code","metadata":{"id":"N03JGeSB8QFj","colab_type":"code","colab":{},"outputId":"fb17b22f-9824-4515-d8cc-fa6e6a8f5d35"},"source":["# Create input tweets for testing the service \n","tweets = {'tweets':['The seat was comfortable! and the bathroom was clean and food was great...',\n","                    'The flight attendant was nice ### but the temperature was cold ---',\n","                    'The movie was not funny at all and the drinks were very bad...',\n","                    'huh uhgyrt jjkoj . g red jgh kh kj k',\n","                    'I was told that the flight would be bad but actually it was very good, thanks US Ailine',\n","                    'I was told that the flight would be good but actually it was very bad, thanks US Ailine'\n","                   ],\n","          'sentiments':['positive',\n","                       'neutral',\n","                       'negative',\n","                       'neutral',\n","                       'positive',\n","                       'negative'\n","                      ]\n","         } \n","  \n","# Create DataFrame \n","df = pd.DataFrame(tweets) \n","  \n","# Print the output. \n","df "],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentiments</th>\n","      <th>tweets</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>positive</td>\n","      <td>The seat was comfortable! and the bathroom was...</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>neutral</td>\n","      <td>The flight attendant was nice ### but the temp...</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>negative</td>\n","      <td>The movie was not funny at all and the drinks ...</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>neutral</td>\n","      <td>huh uhgyrt jjkoj . g red jgh kh kj k</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>positive</td>\n","      <td>I was told that the flight would be bad but ac...</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>negative</td>\n","      <td>I was told that the flight would be good but a...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  sentiments                                             tweets\n","0   positive  The seat was comfortable! and the bathroom was...\n","1    neutral  The flight attendant was nice ### but the temp...\n","2   negative  The movie was not funny at all and the drinks ...\n","3    neutral               huh uhgyrt jjkoj . g red jgh kh kj k\n","4   positive  I was told that the flight would be bad but ac...\n","5   negative  I was told that the flight would be good but a..."]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"markdown","metadata":{"id":"XdAcyHMI8QFm","colab_type":"text"},"source":["# Data Preprocessing"]},{"cell_type":"code","metadata":{"id":"2RBWwnZn8QFn","colab_type":"code","colab":{},"outputId":"e855294f-dd7d-48a2-d5f2-b8a419be5dcf"},"source":["sentiments = df[\"sentiments\"].copy()\n","label_encoder = LabelEncoder()\n","sentiments = label_encoder.fit_transform(sentiments)\n","sentiments = keras.utils.to_categorical(sentiments)\n","sentiments[:5]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0., 0., 1.],\n","       [0., 1., 0.],\n","       [1., 0., 0.],\n","       [0., 1., 0.],\n","       [0., 0., 1.]], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"Ihgs9Iu68QFp","colab_type":"code","colab":{}},"source":["# remove URL's from tweets\n","df['clean_tweets'] = df['tweets'].apply(lambda x: re.sub(r'http\\S+', '', x))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ms8ivoKI8QFr","colab_type":"code","colab":{}},"source":["# remove punctuation marks\n","punctuation = '!\"#$%&()*+-/:;<=>?@[\\\\]^_`{|}~'\n","\n","df['clean_tweets'] = df['clean_tweets'].apply(lambda x: ''.join(ch for ch in x if ch not in set(punctuation)))\n","\n","# convert text to lowercase\n","df['clean_tweets'] = df['clean_tweets'].str.lower()\n","\n","# remove numbers\n","df['clean_tweets'] = df['clean_tweets'].str.replace(\"[0-9]\", \" \")\n","\n","# remove whitespaces\n","df['clean_tweets'] = df['clean_tweets'].apply(lambda x:' '.join(x.split()))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1O6YiLBi8QFt","colab_type":"text"},"source":["### Lemmatize (Normalize) Tweets"]},{"cell_type":"code","metadata":{"id":"Lotrsaqy8QFu","colab_type":"code","colab":{}},"source":["# import spaCy's language model\n","nlp = spacy.load('en', disable=['parser', 'ner'])\n","\n","# function to lemmatize text\n","def lemmatization(texts):\n","    output = []\n","    for i in texts:\n","        s = [token.lemma_ for token in nlp(i)]\n","        output.append(' '.join(s))\n","    return output"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y5wDs6V68QFw","colab_type":"code","colab":{}},"source":["df['clean_tweets'] = lemmatization(df['clean_tweets'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6WYmwxrb8QFx","colab_type":"code","colab":{},"outputId":"8ed62a52-85de-4e4a-97ef-9da780d28834"},"source":["df"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentiments</th>\n","      <th>tweets</th>\n","      <th>clean_tweets</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>positive</td>\n","      <td>The seat was comfortable! and the bathroom was...</td>\n","      <td>the seat be comfortable and the bathroom be cl...</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>neutral</td>\n","      <td>The flight attendant was nice ### but the temp...</td>\n","      <td>the flight attendant be nice but the temperatu...</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>negative</td>\n","      <td>The movie was not funny at all and the drinks ...</td>\n","      <td>the movie be not funny at all and the drink be...</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>neutral</td>\n","      <td>huh uhgyrt jjkoj . g red jgh kh kj k</td>\n","      <td>huh uhgyrt jjkoj . g red jgh kh kj k</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>positive</td>\n","      <td>I was told that the flight would be bad but ac...</td>\n","      <td>i be tell that the flight would be bad but act...</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>negative</td>\n","      <td>I was told that the flight would be good but a...</td>\n","      <td>i be tell that the flight would be good but ac...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  sentiments                                             tweets  \\\n","0   positive  The seat was comfortable! and the bathroom was...   \n","1    neutral  The flight attendant was nice ### but the temp...   \n","2   negative  The movie was not funny at all and the drinks ...   \n","3    neutral               huh uhgyrt jjkoj . g red jgh kh kj k   \n","4   positive  I was told that the flight would be bad but ac...   \n","5   negative  I was told that the flight would be good but a...   \n","\n","                                        clean_tweets  \n","0  the seat be comfortable and the bathroom be cl...  \n","1  the flight attendant be nice but the temperatu...  \n","2  the movie be not funny at all and the drink be...  \n","3               huh uhgyrt jjkoj . g red jgh kh kj k  \n","4  i be tell that the flight would be bad but act...  \n","5  i be tell that the flight would be good but ac...  "]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"id":"oqiR-fuL8QFz","colab_type":"code","colab":{}},"source":["X_input = df[\"clean_tweets\"].values"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QEN8qJFF8QF1","colab_type":"code","colab":{},"outputId":"3bc1fc12-0d0e-4aba-a02b-a1bc0b0b8e55"},"source":["y_pred = model.predict(X_input)"],"execution_count":0,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'model' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-b9c8d360ecff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"knPNhI6d8QF3","colab_type":"text"},"source":["# Call the service my_sentiment_analysis with the input data (tweets)"]},{"cell_type":"code","metadata":{"id":"WqpzaFfO8QF3","colab_type":"code","colab":{}},"source":["y_pred = predict(X_input)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"96L8VEI68QF5","colab_type":"text"},"source":["# Show Predictions"]},{"cell_type":"code","metadata":{"id":"EDolRtOO8QF6","colab_type":"code","colab":{},"outputId":"50f45404-6006-4314-9e8d-ed6926ae8df6"},"source":["print (\"Predictions\" + \"\\n\" +str(y_pred.round(1)))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Predictions\n","[[0.1 0.  0.9]\n"," [0.4 0.  0.6]\n"," [0.7 0.  0.2]\n"," [0.  0.9 0.1]\n"," [0.4 0.1 0.6]\n"," [0.4 0.1 0.6]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-oTW2iJO8QF7","colab_type":"code","colab":{},"outputId":"d82b98c8-10e1-40b3-c9ea-60bc63055aca"},"source":["print (\"Actual sentiments\" + \"\\n\" +str(sentiments))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Actual sentiments\n","[[0. 0. 1.]\n"," [0. 1. 0.]\n"," [1. 0. 0.]\n"," [0. 1. 0.]\n"," [0. 0. 1.]\n"," [1. 0. 0.]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pcP7_0s58QF9","colab_type":"text"},"source":["<img src=\"GCP Service Monitoring.png\">"]},{"cell_type":"code","metadata":{"id":"s3phdqVJ8QF-","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}